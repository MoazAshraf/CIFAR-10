{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "INPUT_SHAPE = [32, 32, 3]\n",
    "N_OUTPUT_CLASSES = 10\n",
    "\n",
    "def create_dnn_model(n_hidden=20, n_neurons=100, activation=\"elu\", kernel_initializer=\"he_normal\", lr=0.001):\n",
    "    \"\"\"\n",
    "    Creates a dense neural network\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    model.add(keras.layers.Flatten(input_shape=INPUT_SHAPE))\n",
    "    \n",
    "    # add hidden layers\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(N_OUTPUT_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # configure the model for training\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"],\n",
    "                  optimizer=keras.optimizers.Nadam(learning_rate=lr))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create a validation set\n",
    "X_train_small, X_val, y_train_small, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "LOG_ROOT = 'train_logs'\n",
    "\n",
    "def generate_log_dir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(LOG_ROOT, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 40000 samples, validate on 10000 samples\nEpoch 1/1000\n40000/40000 - 11s - loss: 5.6913 - accuracy: 0.1673 - val_loss: 2.1734 - val_accuracy: 0.2187\nEpoch 2/1000\n40000/40000 - 9s - loss: 2.0849 - accuracy: 0.2384 - val_loss: 2.0462 - val_accuracy: 0.2477\nEpoch 3/1000\n40000/40000 - 9s - loss: 1.9735 - accuracy: 0.2787 - val_loss: 1.9881 - val_accuracy: 0.2753\nEpoch 4/1000\n40000/40000 - 9s - loss: 1.8931 - accuracy: 0.3085 - val_loss: 1.8513 - val_accuracy: 0.3300\nEpoch 5/1000\n40000/40000 - 9s - loss: 1.8316 - accuracy: 0.3359 - val_loss: 1.8289 - val_accuracy: 0.3349\nEpoch 6/1000\n40000/40000 - 9s - loss: 1.7810 - accuracy: 0.3535 - val_loss: 1.8002 - val_accuracy: 0.3568\nEpoch 7/1000\n40000/40000 - 9s - loss: 1.7429 - accuracy: 0.3696 - val_loss: 1.7504 - val_accuracy: 0.3682\nEpoch 8/1000\n40000/40000 - 10s - loss: 1.6970 - accuracy: 0.3867 - val_loss: 1.7966 - val_accuracy: 0.3546\nEpoch 9/1000\n40000/40000 - 9s - loss: 1.6612 - accuracy: 0.4005 - val_loss: 1.6890 - val_accuracy: 0.3937\nEpoch 10/1000\n40000/40000 - 9s - loss: 1.6340 - accuracy: 0.4096 - val_loss: 1.7505 - val_accuracy: 0.3664\nEpoch 11/1000\n40000/40000 - 9s - loss: 1.6035 - accuracy: 0.4238 - val_loss: 1.6352 - val_accuracy: 0.4160\nEpoch 12/1000\n40000/40000 - 9s - loss: 1.5801 - accuracy: 0.4302 - val_loss: 1.6268 - val_accuracy: 0.4170\nEpoch 13/1000\n40000/40000 - 10s - loss: 1.5605 - accuracy: 0.4383 - val_loss: 1.6018 - val_accuracy: 0.4265\nEpoch 14/1000\n40000/40000 - 9s - loss: 1.5413 - accuracy: 0.4417 - val_loss: 1.6378 - val_accuracy: 0.4116\nEpoch 15/1000\n40000/40000 - 9s - loss: 1.5260 - accuracy: 0.4467 - val_loss: 1.6028 - val_accuracy: 0.4286\nEpoch 16/1000\n40000/40000 - 9s - loss: 1.5067 - accuracy: 0.4563 - val_loss: 1.5969 - val_accuracy: 0.4282\nEpoch 17/1000\n40000/40000 - 9s - loss: 1.4928 - accuracy: 0.4627 - val_loss: 1.6096 - val_accuracy: 0.4241\nEpoch 18/1000\n40000/40000 - 9s - loss: 1.4797 - accuracy: 0.4666 - val_loss: 1.5889 - val_accuracy: 0.4301\nEpoch 19/1000\n40000/40000 - 9s - loss: 1.4582 - accuracy: 0.4763 - val_loss: 1.5914 - val_accuracy: 0.4347\nEpoch 20/1000\n40000/40000 - 9s - loss: 1.4499 - accuracy: 0.4779 - val_loss: 1.5839 - val_accuracy: 0.4368\nEpoch 21/1000\n40000/40000 - 9s - loss: 1.4319 - accuracy: 0.4855 - val_loss: 1.5562 - val_accuracy: 0.4501\nEpoch 22/1000\n40000/40000 - 9s - loss: 1.4268 - accuracy: 0.4883 - val_loss: 1.5783 - val_accuracy: 0.4419\nEpoch 23/1000\n40000/40000 - 9s - loss: 1.4144 - accuracy: 0.4911 - val_loss: 1.5629 - val_accuracy: 0.4388\nEpoch 24/1000\n40000/40000 - 9s - loss: 1.3989 - accuracy: 0.4968 - val_loss: 1.5739 - val_accuracy: 0.4445\nEpoch 25/1000\n40000/40000 - 9s - loss: 1.3890 - accuracy: 0.5017 - val_loss: 1.5468 - val_accuracy: 0.4514\nEpoch 26/1000\n40000/40000 - 9s - loss: 1.3770 - accuracy: 0.5052 - val_loss: 1.5352 - val_accuracy: 0.4572\nEpoch 27/1000\n40000/40000 - 9s - loss: 1.3687 - accuracy: 0.5082 - val_loss: 1.5607 - val_accuracy: 0.4521\nEpoch 28/1000\n40000/40000 - 10s - loss: 1.3573 - accuracy: 0.5134 - val_loss: 1.5453 - val_accuracy: 0.4554\nEpoch 29/1000\n40000/40000 - 9s - loss: 1.3463 - accuracy: 0.5178 - val_loss: 1.5296 - val_accuracy: 0.4606\nEpoch 30/1000\n40000/40000 - 9s - loss: 1.3352 - accuracy: 0.5172 - val_loss: 1.5521 - val_accuracy: 0.4540\nEpoch 31/1000\n40000/40000 - 9s - loss: 1.3253 - accuracy: 0.5240 - val_loss: 1.5544 - val_accuracy: 0.4547\nEpoch 32/1000\n40000/40000 - 9s - loss: 1.3150 - accuracy: 0.5258 - val_loss: 1.5518 - val_accuracy: 0.4577\nEpoch 33/1000\n40000/40000 - 9s - loss: 1.3067 - accuracy: 0.5296 - val_loss: 1.5573 - val_accuracy: 0.4529\nEpoch 34/1000\n40000/40000 - 9s - loss: 1.2948 - accuracy: 0.5353 - val_loss: 1.5423 - val_accuracy: 0.4587\nEpoch 35/1000\n40000/40000 - 9s - loss: 1.2867 - accuracy: 0.5353 - val_loss: 1.5637 - val_accuracy: 0.4544\nEpoch 36/1000\n40000/40000 - 9s - loss: 1.2765 - accuracy: 0.5417 - val_loss: 1.5637 - val_accuracy: 0.4602\nEpoch 37/1000\n40000/40000 - 9s - loss: 1.2681 - accuracy: 0.5431 - val_loss: 1.5484 - val_accuracy: 0.4651\nEpoch 38/1000\n40000/40000 - 9s - loss: 1.2600 - accuracy: 0.5460 - val_loss: 1.5886 - val_accuracy: 0.4535\nEpoch 39/1000\n40000/40000 - 8s - loss: 1.2545 - accuracy: 0.5482 - val_loss: 1.5750 - val_accuracy: 0.4543\nEpoch 40/1000\n40000/40000 - 9s - loss: 1.2434 - accuracy: 0.5511 - val_loss: 1.5408 - val_accuracy: 0.4665\nEpoch 41/1000\n40000/40000 - 9s - loss: 1.2335 - accuracy: 0.5566 - val_loss: 1.5950 - val_accuracy: 0.4566\nEpoch 42/1000\n40000/40000 - 9s - loss: 1.2272 - accuracy: 0.5615 - val_loss: 1.5822 - val_accuracy: 0.4595\nEpoch 43/1000\n40000/40000 - 9s - loss: 1.2167 - accuracy: 0.5598 - val_loss: 1.5869 - val_accuracy: 0.4565\nEpoch 44/1000\n40000/40000 - 9s - loss: 1.2082 - accuracy: 0.5644 - val_loss: 1.5769 - val_accuracy: 0.4532\nEpoch 45/1000\n40000/40000 - 8s - loss: 1.2012 - accuracy: 0.5663 - val_loss: 1.5865 - val_accuracy: 0.4586\nEpoch 46/1000\n40000/40000 - 8s - loss: 1.1910 - accuracy: 0.5705 - val_loss: 1.5752 - val_accuracy: 0.4624\nEpoch 47/1000\n40000/40000 - 9s - loss: 1.1851 - accuracy: 0.5710 - val_loss: 1.5501 - val_accuracy: 0.4675\nEpoch 48/1000\n40000/40000 - 8s - loss: 1.1774 - accuracy: 0.5757 - val_loss: 1.5710 - val_accuracy: 0.4676\nEpoch 49/1000\n40000/40000 - 8s - loss: 1.1687 - accuracy: 0.5790 - val_loss: 1.6000 - val_accuracy: 0.4546\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f98202afd30>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# create and train a basic DNN model\n",
    "model = create_dnn_model(lr=5e-5)\n",
    "\n",
    "model_filepath = \"models/dnn.h5\"\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(keras.callbacks.EarlyStopping(patience=20))\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir=generate_log_dir()))\n",
    "callbacks.append(keras.callbacks.ModelCheckpoint(model_filepath, save_best_only=True))\n",
    "\n",
    "model.fit(X_train_small, y_train_small, validation_data=(X_val, y_val), epochs=1000, callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 1s 70us/sample - loss: 1.5296 - accuracy: 0.4606\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1.52964987449646, 0.4606]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = keras.models.load_model(\"models/dnn.h5\")\n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the lowest validation loss reaches 46.1% validation accuracy. It took 49 epochs to reach this result.\n",
    "\n",
    "Let's see if Batch Normalization will improve the performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit5171d068c3054b8f80dd7b7dde0249a4",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}